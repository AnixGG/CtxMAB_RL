# Contextual Multi-Armed Bandits

This repository provides **modular implementations** of bandit algorithms, including:  

### ðŸ”¹ **Classic (Non-Contextual) Bandits**  
- `Îµ-Greedy`  
- `UCB1` / `UCB2` 
- `Thompsom-Sampling`

### ðŸ”¹ **Contextual Bandits**  
- `LinUCB` (linear UCB)  
- `LinUCB wit OHE arms`
- `Adaptive LinUCB`
- `Decaying Alpha LinUCB`


![plot](./data/regret.png)